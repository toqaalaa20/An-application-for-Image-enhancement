{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8d65922",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense,Input, Conv2D, MaxPooling2D, UpSampling2D, Reshape, Lambda, Flatten, Concatenate, Conv2DTranspose\n",
    "from tensorflow.keras.backend import clear_session\n",
    "from tensorflow.keras.models import Model\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ba246da",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_path= \"D:\\\\M\\\\Exposure_dataset\\\\training\"\n",
    "validation_path= \"D:\\\\M\\\\Exposure_dataset\\\\validation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df623333",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38197515",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6dcde1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7070 images belonging to 2 classes.\n",
      "Found 300 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "image_height= None\n",
    "image_width= None\n",
    "batch_size = 8\n",
    "data_generator = ImageDataGenerator(\n",
    "    rescale=1.0 / 255, \n",
    ")\n",
    "train_data_generator = data_generator.flow_from_directory(\n",
    "    training_path,\n",
    "    target_size=(image_height, image_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='input', \n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_data_generator = data_generator.flow_from_directory(\n",
    "    validation_path,\n",
    "    target_size=(image_height, image_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='input',  \n",
    "    shuffle=False  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53bee32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder(inputs):\n",
    "    conv1 = Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    conv1 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv1)\n",
    "    return conv1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "40afb7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape= (512, 128,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf9b1d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input(shape=input_shape)\n",
    "\n",
    "\n",
    "conv1= encoder(inputs)\n",
    "\n",
    "pool1 = MaxPooling2D((2, 2))(conv1)  \n",
    "\n",
    "conv2 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool1)\n",
    "conv2 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv2)\n",
    "pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "# Decoder (upsampling)\n",
    "up1 = Conv2DTranspose(128, (3, 3), activation='relu', padding='same', strides=(2, 2))(pool2)\n",
    "\n",
    "concat1 = Concatenate(axis=-1)([conv2, up1])\n",
    "conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(concat1)\n",
    "conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv3)\n",
    "\n",
    "up2 = Conv2DTranspose(64, (3, 3), activation='relu', padding='same', strides=(2, 2))(conv3)\n",
    "\n",
    "concat2 = Concatenate(axis=-1)([conv1, up2])\n",
    "\n",
    "conv4 = Conv2D(64, (3, 3), activation='relu', padding='same')(concat2)\n",
    "conv4 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv4)\n",
    "output = Conv2D(3, (1,1), activation='linear')(conv4)\n",
    "# print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "21f45f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=inputs, outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9a7889",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5699f10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "steps_per_epoch = len(train_data_generator)\n",
    "validation_steps = len(val_data_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e784686",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_data_generator,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    epochs=epochs,\n",
    "    validation_data=val_data_generator,\n",
    "    validation_steps=validation_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293d533e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9744157",
   "metadata": {},
   "outputs": [],
   "source": [
    "test= \"M:\\\\Exposure_dataset\\\\testing\\\\INPUT_IMAGES\\\\a0018-kme_234_P1.JPG\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd7d8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "img= cv2.imread(test)\n",
    "img,\n",
    "img= cv2.resize(img, (128, 128))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e9e920",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a367d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.expand_dims(img, axis=0)  \n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5ebb39",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre= model.predict(img)\n",
    "enhanced_image = (pre[0]).astype(np.uint8)\n",
    "enhanced_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43161c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(enhanced_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78f35b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51b0877",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
